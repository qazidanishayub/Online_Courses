{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Bayesian Linear Regression\n",
    "\n",
    "**Author: Khal Makhoul, W.P.G.Peterson**\n",
    "\n",
    "**_Revised: Jessica Cervi_**\n",
    "\n",
    "**Expected time = 3 hours**\n",
    "\n",
    "**Total points = 90 points**\n",
    "  \n",
    "\n",
    "## Assignment Overview\n",
    "\n",
    "This assignment will test your abilities in two different parts. In the first part,  we will revisit Bayes' formula and evaluate your ability to calculate simple Bayesian posterior probabilities. In the second part, we will ask you to build functions that calculate the parameters of Bayesian posteriors for Bayesian Linear Regression. \n",
    "\n",
    "This assignment is designed to build your familiarity and comfort coding in Python while also helping you review key topics from each module. As you progress through the assignment, answers will get increasingly complex. It is important that you adopt a data scientist's mindset when completing this assignment. **Remember to run your code from each cell before submitting your assignment.** Running your code beforehand will notify you of errors and give you a chance to fix your errors before submitting it. You should view your Vocareum submission as if you are delivering a final project to your manager or client. \n",
    "\n",
    "***Vocareum Tips***\n",
    "- Do not add arguments or options to functions unless asked specifically. This will cause an error in Vocareum.\n",
    "- Do not use a library unless asked explicitly in the question. \n",
    "- You can download the Grading Report after submitting the assignment. It will include the feedback and hints on the incorrect questions. \n",
    "\n",
    "\n",
    "### Learning Objectives \n",
    "\n",
    "- Test the fundamental Bayesian knowledge, particularly regarding Linear Regression\n",
    "- List the components of Bayesian theorem \n",
    "- Compute the posterior probabilities \n",
    "- Determine the regression coefficients using the Maximum A Posterior (MAP) inference \n",
    "- Estimate the covariants and the noise in data \n",
    "- Predict the continuous target using Bayesian models \n",
    "\n",
    "\n",
    "\n",
    "## Index: \n",
    "\n",
    "#### Bayesian Linear Regression  \n",
    "\n",
    "- [Question 1](#q1)\n",
    "- [Question 2](#q2)\n",
    "- [Question 3](#q3)\n",
    "- [Question 4](#q4)\n",
    "- [Question 5](#q5)\n",
    "- [Question 6](#q6)\n",
    "- [Question 7](#q7)\n",
    "- [Question 8](#q8)\n",
    "- [Question 9](#q9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Linear Regression\n",
    "\n",
    "\n",
    "In statistics, Bayesian linear regression is an approach that takes on the statistical analysis within the context of Bayesian inference. Bayesian Regression comes with a different toolset than ordinary Linear Regression. Therefore, for this reason, it demands a slightly different mindset.\n",
    "\n",
    "\n",
    "For example, in Bayesian statistical inference, the **prior probability** distribution, often known as the prior, is an important concept. The prior of an uncertain quantity is the probability distribution that would express one's beliefs about this quantity without considering any evidence. \n",
    "For example, we can calculate the prior by surveying people and asking them two questions (What's your age?; Do you watch YouTube every day?), then tabulating the percentage of each age group that watches YouTube every day.\n",
    "\n",
    "\n",
    "To better understand this, we will start with a simple example to highlight how Bayesian thinking proceeds.\n",
    "\n",
    "Consider a population whose age distribution is as follows:\n",
    "\n",
    "| Age group | $\\%$ of total population   |\n",
    "|------|------|\n",
    "|   $\\le 35$  | $25 \\%$|\n",
    "| $36-65$ | $45 \\%$ |\n",
    "| $\\ge 66$ | $30 \\%$|\n",
    "\n",
    "Say, you know the following results of a study about YouTube viewing habits:\n",
    "\n",
    "| Age group | $\\%$ in this group that watch YouTube every day  |\n",
    "|------|------|\n",
    "|   $\\le 35$  | $90 \\%$|\n",
    "| $36-65$ | $50 \\%$  |\n",
    "| $\\ge 66$ | $10 \\%$ |\n",
    "\n",
    "**Question: If you know a user watches YouTube every day, what is the probability that they are under 35?**\n",
    "\n",
    "\n",
    "We will start with a prior, then update that prior using the likelihood and the normalization from Bayes's formula. We define the following notation:\n",
    "\n",
    "* $A$: YouTube watching habit\n",
    "* $B$: Age\n",
    "* $A = 1$: User watches YouTube every day \n",
    "* $A = 0$: User does not watch YouTube every day\n",
    "* $B \\le 35$: User has age less than 36\n",
    "* $36 \\le B \\le 65$: User has age between 36 and 65\n",
    "* $B \\ge  66$: User has age greater than 65\n",
    "\n",
    "The prior can be read from the first table: \n",
    "\n",
    "$$P(B \\le 35) = 0.25$$\n",
    "\n",
    "We can translate the question asked in this exercise into a mathematical language by calculating the posterior probability:\n",
    "\n",
    "$$P(B \\le 35|A = 1)$$\n",
    "\n",
    "by using **Bayes's formula**:\n",
    "\n",
    "$$P(B|A) = \\frac{P(A|B)P(B)}{P(A)}.$$\n",
    "\n",
    "Then, for our question, we obtain:\n",
    "\n",
    "$$P(B \\le 35|A=1) = \\frac{P(A=1|B \\le 35)*P(B \\le 35)}{P(A=1)}$$  \n",
    "\n",
    "Where, observe that, although the tables do not contain the value of $P(A=1)$, we can calculate it as follows:  \n",
    "\n",
    "$$P(A=1) =  P(A=1| B\\le 35)*P(B\\le 35) \\ +  P(A=1|35<B<65)* P(35<B<65)\\  +  P(A=1|B\\ge 65)*P(B\\ge 65)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q1'></a>\n",
    "\n",
    "### Question 1:\n",
    "\n",
    "*5 points*\n",
    "\n",
    "In the example above, P(A=1|B<35) is the:\n",
    "- a) prior\n",
    "- b) liklihood\n",
    "- c) nomalization\n",
    "- d) posterior\n",
    "\n",
    "Assign the character associated with your choice as string to `ans1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "ans1 = 'b'\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 01",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q2'></a>\n",
    "\n",
    "### Question 2:\n",
    "\n",
    "*5 points*\n",
    "\n",
    "Given the values in the tables above, calculate the posterior probability:\n",
    "\n",
    "\"If you know a user watches Youtube every day, what is the probability that they are under 35?\"\n",
    "\n",
    "Assign float to `ans2`. Note that because we are computing a probability, your answer should take a value between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "ans2 = float(.46875)  # (.90)*(0.25)/{p(A=1)= .48 = [(0.9*0.25)+(0.45*0.50)+(0.30*0.10)]}\n",
    "\n",
    "###  \n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 02",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q3'></a>\n",
    "\n",
    "### Question 3:\n",
    "\n",
    "*10 points*\n",
    "\n",
    "Code a function called `calc_posterior`. Your function should accept three inputs: the likelihood and the prior as floats and one list of tuples. Each tuple should contain two values $P(B)$ and $P(A|B)$.\n",
    "\n",
    "You may assume that the list of tuples accounts for all potential values of B and that those values of B are all mutually exclusive.\n",
    "\n",
    "Your function should return a float corresponding to the posterior probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "def calc_posterior(likelihood, prior, norm_list):\n",
    "    \"\"\"\n",
    "    Calculate the posterior probability given likelihood,\n",
    "    prior, and normalization\n",
    "    \n",
    "    Positional Arguments:\n",
    "        likelihood -- float, between 0 and 1\n",
    "        prior -- float, between 0 and 1\n",
    "        norm_list -- list of tuples, each tuple has two values\n",
    "            the first value corresponding to the probability of a value of \"b\"\n",
    "            the second value corresponding to the probability of \n",
    "                a value of \"a\" given that value of \"b\"\n",
    "    Example:\n",
    "        likelihood = .8\n",
    "        prior = .3\n",
    "        norm_list = [(.25 , .9), (.5, .5), (.25,.2)]\n",
    "        print(calc_posterior(likelihood, prior, norm_list))\n",
    "        # --> 0.45714285714285713\n",
    "    \"\"\"\n",
    "    \n",
    "    numerator = likelihood * prior\n",
    "    denominator = sum([x[0]*x[1] for x in norm_list])\n",
    "    \n",
    "    return numerator / denominator\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 03",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data set and exploratory data analysis\n",
    "\n",
    "For this assignment, we will use a regression model on a housing price dataset to predict house price using above-ground living area. More information about this dataset can be found [here](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data).  \n",
    "\n",
    "Before coding an algorithm, we will take a look at our data using `Python`'s `pandas`. For visualizations, we will use `matplotlib`.\n",
    "\n",
    "Let's import the necessary libraries and load the datasets. We will be using using the pandas `pd.read_csv()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Importing the necessary libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Read in the data\n",
    "data = pd.read_csv('./data/train.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by performing some basic exploratory data analysis by using the function `head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's plot the relationship between our variables of interest: the price for each house and the above-ground living area in square feet.\n",
    "\n",
    "We can do so by creating a scatter plot using `matplotlib`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.plot('GrLivArea', 'SalePrice', kind = 'scatter', marker = 'x');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, we are also interested in predicting the price for each house based on the year each house was built. Again, we use `matplotlib` to create a scatter plot of these two variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.plot('YearBuilt', 'SalePrice', kind = 'scatter', marker = 'x');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Bayesian Linear Regression\n",
    "\n",
    "In lecture, we obtained the equation for the posterior probability of $w$, the linear regression parameter vector:\n",
    "\n",
    "$$p(w|y, X) = N(w|\\mu, \\Sigma)$$\n",
    "\n",
    "Where,\n",
    "\n",
    "$$\\Sigma = (\\lambda \\ I + \\sigma^{- 2}\\ X^T\\ X)^{−1}$$\n",
    "\n",
    "$$w_{MAP} = (\\lambda \\ \\sigma^2 I + X^T\\ X)^{-1}\\ X^T y $$\n",
    "\n",
    "\n",
    "\n",
    "Recall that $\\sigma^2$ is a parameter characterizing the deviation of the data from the line defined by $Xw$. While we don't know the true underlying parameter, we can estimate it by using the empirical deviation:\n",
    "\n",
    "$$\\sigma^2  = \\frac{1}{n − d}\\sum_{i=1}^n ( y_i − X_i w )^2$$  \n",
    "Where $w$ in the above line is the $w_{LeastSquares} = (X^T\\ X)^{-1}\\ X^T y$\n",
    "\n",
    "When it comes to make the prediction, we can use the following formulas:\n",
    "\n",
    "$$p( y_0|x_0,y,X) = N(y_0|\\mu_0,\\sigma^2_0)$$  \n",
    "\n",
    "$$\\mu_0 = x^T_0\\mu$$\n",
    "\n",
    "$$ \\sigma^2_0 = \\sigma^2 + x_0^T\\Sigma x_0$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q4'></a>\n",
    "\n",
    "### Question 4:\n",
    "\n",
    "*10 points*\n",
    "\n",
    "In this question, we will start defining the functions to compute Bayesian linear regression from scratch. The first step we need to do, is to prepare our matrix of inputs `X`. This is similar to what we have done in the previous assignments about linear regression and Ridge regression.\n",
    "\n",
    "Define the function called `x_preprocess` that takes, as input, a one- or two-dimensional `NumPy` array. If input is two dimensional, make sure there are more rows than columns.\n",
    "Your function should prepend a column of ones to `X` for the intercept term and return that array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "def x_preprocess(input_x):\n",
    "    \"\"\"\n",
    "    Reshape the input (if needed), and prepend \"1\" to each observation\n",
    "    \n",
    "    Positional Argument:\n",
    "        input_x -- a NumPy array, one- or two-dimensional\n",
    "    \n",
    "    Example:\n",
    "        input1 = np.array([[2,3,6,9],[4,5,7,10]])\n",
    "        input2 = np.array([2,3,6])\n",
    "        input3 = np.array([[2,4],[3,5],[6,7],[9,10]])\n",
    "        \n",
    "        for i in [input1, input2, input3]:\n",
    "            print(x_preprocess(i), \"\\n\")\n",
    "            \n",
    "        # -->[[ 1.  2.  4.]\n",
    "              [ 1.  3.  5.]\n",
    "              [ 1.  6.  7.]\n",
    "              [ 1.  9. 10.]] \n",
    "\n",
    "            [1 2 3 6] \n",
    "\n",
    "            [[ 1.  2.  4.]\n",
    "             [ 1.  3.  5.]\n",
    "             [ 1.  6.  7.]\n",
    "             [ 1.  9. 10.]] \n",
    "\n",
    "    Assumptions:\n",
    "        Assume that if the input is two dimensional, the observations are more numerous\n",
    "            than the features. Thus, the observations should be the rows, and features the columns\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check to see if 1 or 2 dimensions\n",
    "    shape = input_x.shape\n",
    "    if len(shape) == 2:\n",
    "        # If wide, transpose to long\n",
    "        if shape[0]<shape[1]:\n",
    "            input_x = input_x.T\n",
    "            shape = input_x.shape\n",
    "        # create column of ones\n",
    "        ones = np.ones((shape[0],1))\n",
    "        #add colum, of ones\n",
    "        input_x = np.concatenate((ones, input_x), axis = 1)\n",
    "    # If one-dimensional, simply prepend a 1\n",
    "    else:\n",
    "        input_x = np.insert(input_x,0,1)\n",
    "    \n",
    "    return input_x\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 04",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q5'></a>\n",
    "\n",
    "### Question 5:\n",
    "\n",
    "*10 points*\n",
    "\n",
    "In this question, we will calculate the Maximum A Posteriori (MAP) weights according to the formula:\n",
    "\n",
    "$$w_{MAP} = (\\lambda \\ \\sigma^2 I + X^T\\ X)^{-1}\\ X^T y. $$ \n",
    "\n",
    "Define the function called `calculate_map_coefficients` that takes the four inputs: two numpy arrays- an X-matrix and y-vector; two positive numbers- the $\\lambda$ parameter and value for $\\sigma^2$. Your function should return a one-dimensional `NumPy` vector of weights that are computed using the formula given above.\n",
    "\n",
    "Again, you may assume that your X-matrix has been preprocessed in such a way that it should prepend a column of ones, the observations are in the rows, and the features are in the columns.\n",
    "\n",
    "\n",
    "**NOTE:** The functions `.shape`, `np.matmul`, `np.linalg.inv`, `np.ones`, `np.identity`, and `np.transpose` will be valuable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "def calculate_map_coefficients(aug_x, output_y, lambda_param, sigma_squared):\n",
    "    \"\"\"\n",
    "    Calculate the maximum a posteriori LR parameters\n",
    "    \n",
    "     Positional arguments:\n",
    "        aug_x -- x-matrix of training input data, augmented with column of 1's\n",
    "        output_y -- vector of training output values\n",
    "        lambda_param -- positive number; lambda parameter that\n",
    "            controls how heavily to penalize large coefficient values\n",
    "        sigma_squared -- data noise estimate\n",
    "        \n",
    "    Example:\n",
    "        output_y = np.array([208500, 181500, 223500, \n",
    "                             140000, 250000, 143000, \n",
    "                             307000, 200000, 129900, \n",
    "                             118000])\n",
    "                             \n",
    "        aug_x = np. array([[   1., 1710., 2003.],\n",
    "                           [   1., 1262., 1976.],\n",
    "                           [   1., 1786., 2001.],\n",
    "                           [   1., 1717., 1915.],\n",
    "                           [   1., 2198., 2000.],\n",
    "                           [   1., 1362., 1993.],\n",
    "                           [   1., 1694., 2004.],\n",
    "                           [   1., 2090., 1973.],\n",
    "                           [   1., 1774., 1931.],\n",
    "                           [   1., 1077., 1939.]])\n",
    "                           \n",
    "        lambda_param = 0.01\n",
    "        \n",
    "        sigma_squared = 1000\n",
    "        \n",
    "        map_coef = calculate_map_coefficients(aug_x, output_y, \n",
    "                                             lambda_param, sigma_squared)\n",
    "                                             \n",
    "        ml_coef = calculate_map_coefficients(aug_x, output_y, 0,0)\n",
    "        \n",
    "        print(map_coef)\n",
    "        # --> np.array([-576.67947107   77.45913349   31.50189177])\n",
    "        \n",
    "        print(ml_coef)\n",
    "        #--> np.array([-2.29223802e+06  5.92536529e+01  1.20780450e+03])\n",
    "        \n",
    "    Assumptions:\n",
    "        -- output_y is a vector whose length is the same as the\n",
    "        number of rows in input_x\n",
    "        -- aug_x has more observations than it does features.\n",
    "        -- lambda_param has a value greater than 0\n",
    "    \"\"\"\n",
    "    coefs = np.array([])\n",
    "    # Create lambda_matrix: square, with size of columns in augmented x matrix,\n",
    "    # # with the lambda_parameter times sigma on the diagonal\n",
    "    lambda_matrix = lambda_param * sigma_squared* np.identity(aug_x.shape[1])\n",
    "    \n",
    "    # Calculating inverse term\n",
    "    inv = np.linalg.inv(lambda_matrix + np.matmul(np.transpose(aug_x), aug_x))\n",
    "    \n",
    "    # multiply by X-Transpose again\n",
    "    left_multiplier = np.matmul(inv , np.transpose(aug_x))\n",
    "    \n",
    "    # final matrix multiplication with y-vector\n",
    "    coefs = np.matmul(left_multiplier, output_y)\n",
    "    \n",
    "    return coefs\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 05",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q6'></a>\n",
    "\n",
    "### Question 6:\n",
    "\n",
    "*10 points*\n",
    "\n",
    "Next, we will calculate the empirical data noise estimate according to the formula:\n",
    "\n",
    "$$\\sigma^2 = \\frac{1}{n − d}\\Sigma_{i=1}^n ( y_i − X_i w )^2$$  \n",
    "\n",
    "Define the function called `esimate_data_noise` that takes, three inputs: three `NumPy` arrays - One matrix corresponding to the augmented X-matrix and the two vectors- the y-target and the MAP weights.\n",
    "\n",
    "Your function should return the empirical data noise estimate, $\\sigma^2$, calculated with the equation given above.\n",
    "\n",
    "**Note:** In the formula above, \"n\" is the number of observations in X (rows) and \"d\" is the number of features in aug_x (columns). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "def estimate_data_noise(aug_x, output_y, weights):\n",
    "    \"\"\"Return empirical data noise estimate \\sigma^2\n",
    "    Use the LR weights in the equation supplied above\n",
    "    \n",
    "    Positional arguments:\n",
    "        aug_x -- matrix of training input data\n",
    "        output_y -- vector of training output values\n",
    "        weights -- vector of LR weights calculated from output_y and aug_x\n",
    "        \n",
    "        \n",
    "    Example:\n",
    "        output_y = np.array([208500, 181500, 223500, \n",
    "                                140000, 250000, 143000, \n",
    "                                307000, 200000, 129900, \n",
    "                                118000])\n",
    "        aug_x = np. array([[   1., 1710., 2003.],\n",
    "                           [   1., 1262., 1976.],\n",
    "                           [   1., 1786., 2001.],\n",
    "                           [   1., 1717., 1915.],\n",
    "                           [   1., 2198., 2000.],\n",
    "                           [   1., 1362., 1993.],\n",
    "                           [   1., 1694., 2004.],\n",
    "                           [   1., 2090., 1973.],\n",
    "                           [   1., 1774., 1931.],\n",
    "                           [   1., 1077., 1939.]])\n",
    "        \n",
    "        ml_weights = calculate_map_coefficients(aug_x, output_y, 0, 0)\n",
    "        \n",
    "        print(ml_weights)\n",
    "        # --> [-2.29223802e+06  5.92536529e+01  1.20780450e+03]\n",
    "        \n",
    "        sig2 = estimate_data_noise(aug_x, output_y, ml_weights)\n",
    "        print(sig2)\n",
    "        #--> 1471223687.1593\n",
    "        \n",
    "    Assumptions:\n",
    "        -- aug_x has more observations than it does features.\n",
    "        -- output_y is a vector whose length is the same as the\n",
    "        number of rows in training_x\n",
    "    \"\"\"\n",
    "    # Assign n and d\n",
    "    n,d = aug_x.shape\n",
    "   \n",
    "    # calculate difference between prediction and actual; square\n",
    "    diff_list = []\n",
    "    \n",
    "    for i in range(len(output_y)):\n",
    "        diff_list.append((output_y[i]- np.matmul(aug_x[i],weights))**2)\n",
    "    \n",
    "    # sum squared differences, scale with n and d\n",
    "    return float((1/(n-d))*sum(diff_list))\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 06",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q7'></a>\n",
    "\n",
    "### Question 7:\n",
    "\n",
    "*10 points*\n",
    "\n",
    "In this question, we will calculate the covariance matrix of the posterior according to the formula:\n",
    "\n",
    "\n",
    "$$\\Sigma = (\\lambda \\ I + \\sigma^{- 2}\\ X^T\\ X)^{−1}.$$\n",
    "\n",
    "Define the function called `calc_post_cov_mtx` that takes three inputs: one `NumPy` array for the augmented x-matrix;\n",
    "two floats for $\\sigma^2$ and $\\lambda$.\n",
    "Your function should return the covariance matrix of the posterior computed using the equation given above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "def calc_post_cov_mtx(aug_x, sigma_squared, lambda_param):\n",
    "    \"\"\"\n",
    "    Calculate the covariance of the posterior for Bayesian parameters.\n",
    "    \n",
    "    Positional arguments:\n",
    "        aug_x -- matrix of training input data; preprocessed\n",
    "        sigma_squared -- estimation of sigma^2\n",
    "        lambda_param -- lambda parameter that controls how heavily\n",
    "        to penalize large weight values\n",
    "        \n",
    "    Example:\n",
    "        output_y = np.array([208500, 181500, 223500, \n",
    "                                140000, 250000, 143000, \n",
    "                                307000, 200000, 129900, \n",
    "                                118000])\n",
    "        aug_x = np. array([[   1., 1710., 2003.],\n",
    "                           [   1., 1262., 1976.],\n",
    "                           [   1., 1786., 2001.],\n",
    "                           [   1., 1717., 1915.],\n",
    "                           [   1., 2198., 2000.],\n",
    "                           [   1., 1362., 1993.],\n",
    "                           [   1., 1694., 2004.],\n",
    "                           [   1., 2090., 1973.],\n",
    "                           [   1., 1774., 1931.],\n",
    "                           [   1., 1077., 1939.]])\n",
    "        lambda_param = 0.01\n",
    "        \n",
    "        ml_weights = calculate_map_coefficients(aug_x, output_y,0,0)\n",
    "        \n",
    "        sigma_squared = estimate_data_noise(aug_x, output_y, ml_weights)\n",
    "        \n",
    "        print(calc_post_cov_mtx(aug_x, sigma_squared, lambda_param))\n",
    "        # --> [[ 9.99999874e+01 -1.95016334e-02 -2.48082095e-02]\n",
    "               [-1.95016334e-02  6.28700339e+01 -3.85675510e+01]\n",
    "               [-2.48082095e-02 -3.85675510e+01  5.10719826e+01]]\n",
    "\n",
    "    Assumptions:\n",
    "        -- aug_x is a vector whose length is the same as the\n",
    "        number of rows in training_x\n",
    "        -- lambda_param has a value greater than 0\n",
    "    \n",
    "    \"\"\"\n",
    "    #Create lambda matrix\n",
    "    lambda_mtx = lambda_param * np.identity(aug_x.shape[1])\n",
    "    #sigma = 0.1\n",
    "    # Implement equation: inverse of lambda plus 1/ sigma times X.T*X\n",
    "    return np.linalg.inv(lambda_mtx+((1/sigma)*np.matmul(aug_x.T, aug_x)))\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 07",
     "locked": true,
     "points": "10",
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "So far, we have coded the functions for\n",
    "\n",
    "$$w_{map}=(\\lambda\\ \\sigma^2 I+X^TX)^{-1}X^Ty$$\n",
    "and\n",
    "\n",
    "$$\\Sigma = (\\lambda \\ I + \\sigma^{- 2}\\ X^T\\ X)^{−1}.$$\n",
    "\n",
    "\n",
    "Therefore, the posterior distribution of the linear regression parameters, $p(w|y, X) = N(w|\\mu, \\Sigma)$,  may be described.\n",
    "\n",
    "\n",
    "[Back to top](#Index:) \n",
    "<a id='q8'></a>\n",
    "\n",
    "### Question 8:\n",
    "\n",
    "*10 points*\n",
    "\n",
    "\n",
    "Recall that, when we want to predict an unknown value, $y_0$, given observations $x_0$, the  point estimate $\\mu_0$, and variance for the prediction for x $\\sigma^2_0$ can be computed via \n",
    "\n",
    "$$\\mu_0 = x^T_0\\mu$$\n",
    "\n",
    "$$\\sigma^2_0 = \\sigma^2 + x_0^T\\Sigma x_0$$\n",
    "\n",
    "\n",
    "Define the function called `predict` that takes four inputs: three `NumPy` arrays, and one number. The three arrays correspond to the one-dimensional array of the augmented_x vector, the vector of the MAP weights, and the square matrix for the $\\Sigma$ term. The positive number corresponds to the $\\sigma^2$ term.\n",
    "\n",
    "Using the above equations, your function should return $\\mu_0$ and $\\sigma^2_0$ according to the equations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "def predict( aug_x, weights, big_sig, sigma_squared):\n",
    "    \"\"\"\n",
    "    Calculate the point estimates and uncertainty for new values of x\n",
    "    \n",
    "    Positional Arguments:\n",
    "        aug_x -- The augmented matrix of observations for predictions\n",
    "        weights -- MAP weights calculated from Bayesian LR\n",
    "        big_sig -- The posterior covarience matrix, from Bayesian LR\n",
    "        sigma_squared -- The observed uncertainty in Bayesian LR\n",
    "        \n",
    "    Example:\n",
    "        output_y = np.array([208500, 181500, 223500, \n",
    "                                140000, 250000, 143000, \n",
    "                                307000, 200000, 129900, \n",
    "                                118000])\n",
    "                                \n",
    "        aug_x = np. array([[   1., 1710., 2003.],\n",
    "                           [   1., 1262., 1976.],\n",
    "                           [   1., 1786., 2001.],\n",
    "                           [   1., 1717., 1915.],\n",
    "                           [   1., 2198., 2000.],\n",
    "                           [   1., 1362., 1993.],\n",
    "                           [   1., 1694., 2004.],\n",
    "                           [   1., 2090., 1973.],\n",
    "                           [   1., 1774., 1931.],\n",
    "                           [   1., 1077., 1939.]])\n",
    "        lambda_param = 0.01\n",
    "        \n",
    "        ml_weights = calculate_map_coefficients(aug_x, output_y,0,0)\n",
    "        \n",
    "        sigma_squared = estimate_data_noise(aug_x, output_y, ml_weights)\n",
    "        \n",
    "        map_weights = calculate_map_coefficients(aug_x, output_y, lambda_param, sigma_squared)\n",
    "        \n",
    "        big_sig = calc_post_cov_mtx(aug_x, sigma_squared, lambda_param)\n",
    "        \n",
    "        to_pred2 = np.array([1,1700,1980])\n",
    "        \n",
    "        print(predict(to_pred2, map_weights, big_sig, sigma_squared))\n",
    "        #-->(158741.6306608729, 1593503867.9060116)\n",
    "        \n",
    "    \"\"\"\n",
    "    # calculate mu term\n",
    "    mu_0 = np.matmul(aug_x.T, weights)\n",
    "    # calculate sigma squared term\n",
    "    #sigma\n",
    "    sig_squared_0 = sigma + np.matmul(np.matmul(aug_x.T, big_sig), aug_x)\n",
    "    \n",
    "    return mu_0, sig_squared_0\n",
    "\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 08",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q9'></a>\n",
    "\n",
    "### Question 9:\n",
    "\n",
    "*20 points*\n",
    "\n",
    "Now it's time to use the functions defined above to make a prediction using our housing dataset.\n",
    "\n",
    "For this question, define two empty `NumPy` arrays, `mu` and `big_sig`.\n",
    "\n",
    "Next, define the `y` target by using the variable \"SalePrice\" and the input `X` by using the variables \"GrLivArea\" and \"YearBuilt\" as predictors.\n",
    "\n",
    "**NOTE**: For grading purposes, keep \"GrLivArea\" and \"YearBuild\", in that order and use all the observations in `data` by using the function `.values`.\n",
    "\n",
    "Set $\\lambda = 0.1$\n",
    "\n",
    "Compute the $w_{\\text{MAP}}$ vector and assign the result to the variable `mu`. Finally, compute the $\\Sigma$ matrix and assign the result to `big_sig`.\n",
    "\n",
    "**HINT: Note that, for this question, you will have to use all the functions you have defined in the previous questions exept for the one you have defined in Question 8.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "\"\"\"\n",
    "Example:\n",
    "    input_x = data[['GrLivArea','YearBuilt']].head(100).values\n",
    "    output_y = data['SalePrice'].head(100).values\n",
    "    lambda_param = .1\n",
    "    \n",
    "    < --- CODE BLOCK --->\n",
    "    \n",
    "    print(mu)\n",
    "    #--> np.array([2.10423243e-02, 4.10449281e+01, 4.22635006e+01])\n",
    "    print(big_sig)\n",
    "    #--> \n",
    "    np.array([[ 9.99999861e+00, -1.75179751e-03, -2.74204060e-03],\n",
    "              [-1.75179751e-03,  6.50420674e+00, -3.47271893e+00],\n",
    "              [-2.74204060e-03, -3.47271893e+00,  4.60297584e+00]])\n",
    "\"\"\"\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "y = data.SalePrice.values\n",
    "X = data[['GrLivArea','YearBuilt']].values\n",
    "X = x_preprocess(X)\n",
    "\n",
    "ml_w = calculate_map_coefficients(X,y, 0,0)\n",
    "\n",
    "sigma = estimate_data_noise(X,y,ml_w)\n",
    "\n",
    "sol_mu = calculate_map_coefficients(X,y,.1, sigma)\n",
    "\n",
    "sol_bs = calc_post_cov_mtx(X,sigma, .1)\n",
    "\n",
    "mu = sol_mu #--> np.array([1.30269779e-02, 7.61463982e+01, 3.22497911e+01])\n",
    "\n",
    "big_sig = sol_bs\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 09",
     "locked": true,
     "points": "20",
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.7]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
